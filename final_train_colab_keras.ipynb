{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TTZDzir3_SbR"
   },
   "source": [
    "# **`Common class`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zKXn9noylj9Q"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import load_model\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras, math\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "class Common:\n",
    "     \n",
    "    def __init__(self, initial_lrate=0.1, drop=0.8, epochs_drop=0.1, limit_inf=0.001):\n",
    "        self.initial_lrate = initial_lrate\n",
    "        self.drop = drop\n",
    "        self.epochs_drop = epochs_drop\n",
    "        self.limit_inf = limit_inf\n",
    "        self.model = None\n",
    "        \n",
    "    def step_decay(self, epoch):\n",
    "        print(\"[+] initial: \", self.initial_lrate)\n",
    "        print(\"[+] ANTIGO K: \", K.eval(self.model.optimizer.lr))\n",
    "\n",
    "        if epoch == 0:\n",
    "            lrate = self.initial_lrate\n",
    "        else:\n",
    "            lrate = self.initial_lrate * math.pow(self.drop, math.floor((1+epoch)/self.epochs_drop))\n",
    "            if lrate <= self.limit_inf:\n",
    "                lrate = self.limit_inf            \n",
    "        print(\"[+] NOVO: \", lrate)\n",
    "        return lrate\n",
    "\n",
    "    def save_plot_losses(self, history, path_dir):\n",
    "        plt.figure(figsize=[8,6])\n",
    "        plt.plot(history.history['loss'],'r',linewidth=3.0)\n",
    "        plt.plot(history.history['val_loss'],'b',linewidth=3.0)\n",
    "        plt.legend(['Custo no Treino', 'Custo no Teste'],fontsize=18)\n",
    "        plt.xlabel('Épocas ',fontsize=16)\n",
    "        plt.ylabel('Custo',fontsize=16)\n",
    "        plt.title('Curvas da Função de Custo',fontsize=16)\n",
    "        plt.savefig(os.path.join(path_dir, 'loss.png'))\n",
    "\n",
    "    def save_plot_acc(self, history, path_dir):\n",
    "        plt.figure(figsize=[8,6])\n",
    "        plt.plot(history.history['acc'],'r',linewidth=3.0)\n",
    "        plt.plot(history.history['val_acc'],'b',linewidth=3.0)\n",
    "        plt.legend(['Acurácia no Treino', 'Acurácia no Teste'],fontsize=18)\n",
    "        plt.xlabel('Épocas ',fontsize=16)\n",
    "        plt.ylabel('Acurácia',fontsize=16)\n",
    "        plt.title('Curvas da Acurácia',fontsize=16)\n",
    "        plt.savefig(os.path.join(path_dir, 'acc.png'))\n",
    "\n",
    "    def write_file_info(self, path_dir, content):\n",
    "        file_info_path = os.path.join(path_dir, \"info.txt\")\n",
    "        file_info_experiment = open(file_info_path, \"a+\")\n",
    "\n",
    "        for i in content:\n",
    "            line = str(i) + \"\\n\"\n",
    "            file_info_experiment.write(line)\n",
    "\n",
    "        file_info_experiment.close()\n",
    "\n",
    "    def addCommentary(self, path_dir, commentary=\"\"):\n",
    "        self.write_file_info(path_dir, [\"commentary: \" + commentary])\n",
    "        \n",
    "    def train(self, model, x_train, y_train, x_test, y_test, batch_size, epochs, path_dir, patience):\n",
    "        self.write_file_info(path_dir, [\"batch_size: \"+str(batch_size)])\n",
    "        \n",
    "        self.model = model\n",
    "\n",
    "        file_weights = os.path.join(path_dir, \"weights.{epoch:02d}-{val_loss:.2f}.hdf5\")\n",
    "        checkpoint = ModelCheckpoint(file_weights, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "#         checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n",
    "        earlystopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=patience, verbose=1, mode='auto')\n",
    "        \n",
    "        lrate = LearningRateScheduler(self.step_decay)\n",
    "        \n",
    "        callbacks_list = [checkpoint, earlystopping, lrate]\n",
    "        print(\"[+] BATCH_SIZE: \", batch_size)\n",
    "        history = self.model.fit(x_train, y_train,\n",
    "                    batch_size = batch_size,\n",
    "                    epochs = epochs,\n",
    "                    verbose = 1,\n",
    "#                     steps_per_epoch = 100,\n",
    "                    shuffle = True,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks = callbacks_list)\n",
    "\n",
    "        return self.model, history\n",
    "\n",
    "    def evaluate(self, model, x_test, y_test):\n",
    "        score = model.evaluate(x_test, y_test, verbose=0)\n",
    "        return score\n",
    "\n",
    "    def compile_net(self, model, path_dir, option):\n",
    "\n",
    "        self.write_file_info(path_dir, [\"learning_rate_initial: \"+str(self.initial_lrate), \\\n",
    "                                        \"learning_rate_inf: \"+str(self.limit_inf), \\\n",
    "                                        \"learnig_rate_drop: \"+ str(self.drop),\\\n",
    "                                        \"learnig_rate_epochs_drop: \"+ str(self.epochs_drop),\\\n",
    "                                        \"optimizer: \" + str(option)])\n",
    "\n",
    "#         print(\"[+] summary network:\")\n",
    "#         print(model.summary())\n",
    "        \n",
    "        self.model = model\n",
    "        print(\"[+] OPTIMIZER: \", option)       \n",
    "        \n",
    "        if option == \"Adadelta\":\n",
    "            self.model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                        optimizer=keras.optimizers.Adadelta(lr=self.initial_lrate),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        elif option == \"Adam\":\n",
    "            self.model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                        optimizer=keras.optimizers.Adam(lr=self.initial_lrate),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        elif option == \"SGD\":\n",
    "            self.model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                        optimizer=keras.optimizers.SGD(lr=self.initial_lrate),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        elif option == \"Nadam\":\n",
    "            self.model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                        optimizer=keras.optimizers.Nadam(lr=self.initial_lrate),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "        elif option == \"RMSprop\":\n",
    "            self.model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "                        optimizer=keras.optimizers.Nadam(lr=self.initial_lrate),\n",
    "                        metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        return self.model\n",
    "\n",
    "    def load_model_net(self, path):\n",
    "        self.model = load_model(path)\n",
    "        return self.model\n",
    "\n",
    "    def last_load_model_net(self, experimental_path):\n",
    "        weights = os.listdir(experimental_path)\n",
    "        weights = sorted(weights, reverse=True)\n",
    "        print(\"[+] WEIGHTS LIST: \", weights)\n",
    "        print(\"[+] WEIGHTS RESTORE: \", weights[0])        \n",
    "        self.model = load_model(os.path.join(experimental_path, weights[0]))\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "    def classify_image(self, model, img):\n",
    "        return model.predict([img])\n",
    "\n",
    "    def classify_image_from_path(self, model, path, dim):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.resize(img, (dim, dim))\n",
    "        img = np.array(img)\n",
    "        img = img.astype('float32')\n",
    "        img = img / 255\n",
    "\n",
    "        img = img.reshape(1, dim, dim, 3)\n",
    "\n",
    "        print(\"shape: \", img.shape)\n",
    "        return model.predict([np.array(img)])\n",
    "\n",
    "    def classify_bath_image_from_path(self, model, path, clazz, dim):\n",
    "        cont = [0, 0]\n",
    "        # print(\"255\")\n",
    "        for file in os.listdir(path):\n",
    "            img = cv2.imread(os.path.join(path, file))\n",
    "            img = cv2.resize(img, (dim, dim))\n",
    "            cv2.imshow(\"img\", img)\n",
    "            cv2.waitKey(200)\n",
    "            img = np.array(img)\n",
    "            img = img.astype('float32')\n",
    "            img = img / 255\n",
    "\n",
    "            img = img.reshape(1, dim, dim, 3)\n",
    "            # print([np.array(img)])\n",
    "            # print(\"shape: \", img.shape)\n",
    "            vet = model.predict([np.array(img)])\n",
    "            # print(\"vet: \", vet)\n",
    "            if np.argmax(vet[0]) == clazz:\n",
    "                cont[0] += 1\n",
    "            else:\n",
    "                cont[1] += 1\n",
    "                print(file)\n",
    "        print(\"Classe: \", clazz, \" Conts: \", cont)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UZvqstQE_EKm"
   },
   "source": [
    "# **`Neural Networks Architectures Keras`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q3rbSw5X_eCq"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class InceptionResNetV2:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.inception_resnet_v2.InceptionResNetV2(include_top=True,\n",
    "                                        weights=None,\n",
    "                                        input_tensor=None,\n",
    "                                        input_shape=input_shape,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1hFE6DN6lh2n"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class NASNetLarge:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.nasnet.NASNetLarge(include_top=True,\n",
    "                                        weights=None,\n",
    "                                        input_tensor=None,\n",
    "                                        input_shape=input_shape,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TA1HSHr915eH"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class Xception:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.xception.Xception(include_top=True,\n",
    "                                        weights=None,\n",
    "                                        input_tensor=None,\n",
    "                                        input_shape=input_shape,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V4gCf7vs_nar"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class InceptionV3:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.inception_v3.InceptionV3(include_top=True,\n",
    "                                        weights=None,\n",
    "                                        input_tensor=None,\n",
    "                                        input_shape=input_shape,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yCPzLp8E_uGf"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class MobileNet:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.mobilenet.MobileNet(input_shape=input_shape,\n",
    "                                                alpha=1.0,\n",
    "                                                depth_multiplier=1,\n",
    "                                                dropout=1e-3,\n",
    "                                                include_top=True,\n",
    "                                                weights=None,\n",
    "                                                input_tensor=None,\n",
    "                                                pooling='max',\n",
    "                                                classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eJa_Q2Nf_yN0"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class MobileNetV2:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.mobilenetv2.MobileNetV2(input_shape=input_shape,\n",
    "                                                alpha=1.0,\n",
    "                                                include_top=False,\n",
    "                                                weights=None,\n",
    "                                                input_tensor=None,\n",
    "                                                pooling='max',\n",
    "                                                classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Tf5vDhQx_24t"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class ResNet50:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.resnet50.ResNet50(include_top=True,\n",
    "                                        input_shape=input_shape,\n",
    "                                        weights=None,\n",
    "                                        input_tensor=None,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1LQCTogq_9TS"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class VGG16:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.vgg16.VGG16(include_top=True,\n",
    "                                        input_tensor=None,\n",
    "                                        weights=None,\n",
    "                                        input_shape=input_shape,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V0WyvOkvAB4p"
   },
   "outputs": [],
   "source": [
    "import keras.applications as classifiers\n",
    "\n",
    "\n",
    "class VGG19:\n",
    "    def build_network(self, input_shape, num_classes):\n",
    "        model = classifiers.vgg16.VGG16(include_top=True,\n",
    "                                        weights=None,\n",
    "                                        input_tensor=None,\n",
    "                                        input_shape=input_shape,\n",
    "                                        pooling='max',\n",
    "                                        classes=num_classes)\n",
    "        return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BAGSiDqCDgx"
   },
   "source": [
    "# **`Utils Class`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1FW0R_l0CIpU"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "class Utils:\n",
    "    def make_dirs(self, path):\n",
    "        if os.path.exists(path) == False:\n",
    "            os.makedirs(path)\n",
    "\n",
    "    def get_date_string(self):\n",
    "        ts = time.time()\n",
    "        st = datetime.datetime.fromtimestamp(ts).strftime('%H_%M_%S+%Y-%m-%d')\n",
    "        return st\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Y9RWTgVePvDJ"
   },
   "source": [
    "# **`Pre Processing Class`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tVUkTskGP0E-"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# from utils.constants import getDataPath\n",
    "# from utils.constants import getDataAndLabelsPath\n",
    "# from utils.constants import getLabelsPath\n",
    "import os\n",
    "\n",
    "class PreProcessing:\n",
    "\n",
    "    def load_base_input_experiment(self, path):\n",
    "        pwd = os.path.join(path, \"training\")\n",
    "        CIFE_TR_DATA = np.load(os.path.join(pwd, 'CIFE-data-tr.npy'))\n",
    "        CIFE_TS_DATA = np.load(os.path.join(pwd, 'CIFE-data-ts.npy'))\n",
    "        CK_DATA = np.load(os.path.join(pwd, 'ck+-data.npy'))\n",
    "        FER_DATA = np.load(os.path.join(pwd, 'fer_data.npy'))\n",
    "        JAFFE_DATA = np.load(os.path.join(pwd, 'JAFFE-data.npy'))\n",
    "        KDEF_DATA = np.load(os.path.join(pwd, 'KDEF-data.npy'))\n",
    "        NOVAEMOTIONS_DATA = np.load(os.path.join(pwd, 'novaemotions-data.npy'))\n",
    "        RAFD_DATA = np.load(os.path.join(pwd, 'RafD-data.npy'))\n",
    "\n",
    "        x_train = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA), axis=0)\n",
    "#         x_train = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, RAFD_DATA), axis=0)\n",
    "\n",
    "        pwd = os.path.join(path, \"training\")\n",
    "        CIFE_TR_DATA = np.load(os.path.join(pwd, 'CIFE-label-tr.npy'))\n",
    "        CIFE_TS_DATA = np.load(os.path.join(pwd, 'CIFE-label-ts.npy'))\n",
    "        CK_DATA = np.load(os.path.join(pwd, 'ck+-label.npy'))\n",
    "        FER_DATA = np.load(os.path.join(pwd, 'fer_labels.npy'))\n",
    "        JAFFE_DATA = np.load(os.path.join(pwd, 'JAFFE-label.npy'))\n",
    "        KDEF_DATA = np.load(os.path.join(pwd, 'KDEF-label.npy'))\n",
    "        NOVAEMOTIONS_DATA = np.load(os.path.join(pwd, 'novaemotions-label.npy'))\n",
    "        RAFD_DATA = np.load(os.path.join(pwd, 'RafD-label.npy'))\n",
    "\n",
    "        y_train = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA), axis=0)\n",
    "#         y_train = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, RAFD_DATA), axis=0)\n",
    "\n",
    "        pwd = os.path.join(path, \"testing\")\n",
    "        CIFE_TR_DATA = np.load(os.path.join(pwd, 'CIFE-data-tr.npy'))\n",
    "        CIFE_TS_DATA = np.load(os.path.join(pwd, 'CIFE-data-ts.npy'))\n",
    "        CK_DATA = np.load(os.path.join(pwd, 'ck+-data.npy'))\n",
    "        FER_DATA = np.load(os.path.join(pwd, 'fer_data.npy'))\n",
    "        JAFFE_DATA = np.load(os.path.join(pwd, 'JAFFE-data.npy'))\n",
    "        KDEF_DATA = np.load(os.path.join(pwd, 'KDEF-data.npy'))\n",
    "        NOVAEMOTIONS_DATA = np.load(os.path.join(pwd, 'novaemotions-data.npy'))\n",
    "        RAFD_DATA = np.load(os.path.join(pwd, 'RafD-data.npy'))\n",
    "\n",
    "        x_test = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA), axis=0)\n",
    "\n",
    "        pwd = os.path.join(path, \"testing\")\n",
    "        CIFE_TR_DATA = np.load(os.path.join(pwd, 'CIFE-label-tr.npy'))\n",
    "        CIFE_TS_DATA = np.load(os.path.join(pwd, 'CIFE-label-ts.npy'))\n",
    "        CK_DATA = np.load(os.path.join(pwd, 'ck+-label.npy'))\n",
    "        FER_DATA = np.load(os.path.join(pwd, 'fer_labels.npy'))\n",
    "        JAFFE_DATA = np.load(os.path.join(pwd, 'JAFFE-label.npy'))\n",
    "        KDEF_DATA = np.load(os.path.join(pwd, 'KDEF-label.npy'))\n",
    "        NOVAEMOTIONS_DATA = np.load(os.path.join(pwd, 'novaemotions-label.npy'))\n",
    "        RAFD_DATA = np.load(os.path.join(pwd, 'RafD-label.npy'))\n",
    "\n",
    "        y_test = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA), axis=0)\n",
    "\n",
    "        return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "    def load_base(self, path):\n",
    "        pwd = os.path.join(path, \"images\")\n",
    "        CIFE_TR_DATA = np.load(os.path.join(pwd, 'CIFE-data-tr.npy'))\n",
    "        CIFE_TS_DATA = np.load(os.path.join(pwd, 'CIFE-data-ts.npy'))\n",
    "        CK_DATA = np.load(os.path.join(pwd, 'ck+-data.npy'))\n",
    "        FER_DATA = np.load(os.path.join(pwd, 'fer_data.npy'))\n",
    "        JAFFE_DATA = np.load(os.path.join(pwd, 'JAFFE-data.npy'))\n",
    "        KDEF_DATA = np.load(os.path.join(pwd, 'KDEF-data.npy'))\n",
    "        NOVAEMOTIONS_DATA = np.load(os.path.join(pwd, 'novaemotions-data.npy'))\n",
    "        RAFD_DATA = np.load(os.path.join(pwd, 'RafD-data.npy'))\n",
    "\n",
    "        images = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA), axis=0)\n",
    "\n",
    "        pwd = os.path.join(path, \"labels\")\n",
    "        CIFE_TR_DATA = np.load(os.path.join(pwd, 'CIFE-label-tr.npy'))\n",
    "        CIFE_TS_DATA = np.load(os.path.join(pwd, 'CIFE-label-ts.npy'))\n",
    "        CK_DATA = np.load(os.path.join(pwd, 'ck+-label.npy'))\n",
    "        FER_DATA = np.load(os.path.join(pwd, 'fer_labels.npy'))\n",
    "        JAFFE_DATA = np.load(os.path.join(pwd, 'JAFFE-label.npy'))\n",
    "        KDEF_DATA = np.load(os.path.join(pwd, 'KDEF-label.npy'))\n",
    "        NOVAEMOTIONS_DATA = np.load(os.path.join(pwd, 'novaemotions-label.npy'))\n",
    "        RAFD_DATA = np.load(os.path.join(pwd, 'RafD-label.npy'))\n",
    "\n",
    "        labels = np.concatenate((CIFE_TR_DATA, CIFE_TS_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA), axis=0)\n",
    "\n",
    "        return images, labels\n",
    "\n",
    "\n",
    "    def generate_images_with_size(self, size, save=True, paths=None, path_output=None, faceDetector=None):\n",
    "        # CIFE_DATA, CK_DATA, FER_DATA, JAFFE_DATA, KDEF_DATA, NOVAEMOTIONS_DATA, RAFD_DATA = getDataPath()\n",
    "        if paths == None:\n",
    "            paths_images = getDataPath()\n",
    "            path_labels = getLabelsPath()\n",
    "\n",
    "        total_images = 0\n",
    "\n",
    "        if len(paths_images) != len(path_labels):\n",
    "            print(\"[+] ERROR PATH LABEL AND IMAGE SIZE DIFFERENCE\")\n",
    "            return False\n",
    "\n",
    "        for index in range(len(paths_images)):\n",
    "            print(\"path: \", paths_images[index])\n",
    "            total_images += self.resize_all_images_label(size, paths_images[index], path_output, path_labels[index], faceDetector, save)\n",
    "\n",
    "        print(\"[+] Total Images: \", total_images)\n",
    "        return True\n",
    "\n",
    "    # def generate_labels(self, save=False, paths=None, path_output=None):\n",
    "    #     if paths == None:\n",
    "    #         paths = getLabelsPath()\n",
    "    #\n",
    "    #     labels = []\n",
    "    #\n",
    "    #     # for path in enumerate(paths):\n",
    "    #     for path in paths:\n",
    "    #         label = np.load(path).tolist()\n",
    "    #         labels += label\n",
    "    #\n",
    "    #     print(\"[+] Labels len: \", len(labels))\n",
    "    #\n",
    "    #     if save == True:\n",
    "    #         self.make_dirs(os.path.join(path_output, \"labels\"))\n",
    "    #         file_name = os.path.join(path_output, \"labels\",  \"labels.npy\")\n",
    "    #         print(\"[+] File Saving: \", file_name)\n",
    "    #         np.save(file_name, labels)\n",
    "    #\n",
    "    #\n",
    "    #     return labels\n",
    "\n",
    "    def load_from_file(self, path):\n",
    "        return np.load(path)\n",
    "\n",
    "    def resize_all_images_label(self, size, path_load, path_output, path_label, faceDetector=None, save=True):\n",
    "        #TODO: Verify others possible resize processing, cubic, linear, etc, upsample\n",
    "        new_images = []\n",
    "        new_labels = []\n",
    "\n",
    "        images = np.load(path_load)\n",
    "        labels = np.load(path_label)\n",
    "\n",
    "        print(\"[+] SIZE: \", size)\n",
    "\n",
    "        if len(images) != len(labels):\n",
    "            print(\"[+] ERROR LABEL AND IMAGE SIZE DIFFERENCE\")\n",
    "            return False\n",
    "\n",
    "        for index in range(len(images)):\n",
    "            coordinates = faceDetector.detectCNN(images[index])\n",
    "\n",
    "            if coordinates != []:\n",
    "                bbox = coordinates[0]\n",
    "                # cv2.imshow(\"img1\", images[index])\n",
    "                # cv2.waitKey(25)\n",
    "                print(index)\n",
    "                img = images[index]\n",
    "                img = img[bbox[0]:bbox[2], bbox[3]:bbox[1]]\n",
    "\n",
    "                img = cv2.resize(img, (size, size))\n",
    "\n",
    "                cv2.imshow(\"img-cropped-RSZ\", img)\n",
    "                cv2.waitKey(10)\n",
    "\n",
    "                new_labels.append(labels[index])\n",
    "                new_images.append(img)\n",
    "\n",
    "        print(\"resized \", path_load, \" :\", len(new_images))\n",
    "        print(\"labels \", path_label, \" :\", len(new_labels))\n",
    "\n",
    "        if save == True:\n",
    "            base_label = os.path.basename(os.path.normpath(path_load))\n",
    "            # base_label = base_label.replace(\".npy\", \"\")\n",
    "\n",
    "            self.make_dirs(os.path.join(path_output, \"images\"))\n",
    "            file_image_name = os.path.join(path_output, \"images\", base_label)\n",
    "            print(\"[+] File Saving: \", file_image_name)\n",
    "            np.save(file_image_name, new_images)\n",
    "\n",
    "            base_label = os.path.basename(os.path.normpath(path_label))\n",
    "            # base_label = base_label.replace(\".npy\", \"\")\n",
    "\n",
    "            self.make_dirs(os.path.join(path_output, \"labels\"))\n",
    "            file_label_name = os.path.join(path_output, \"labels\",  base_label)\n",
    "            print(\"[+] File Saving: \", file_label_name)\n",
    "            np.save(file_label_name, new_labels)\n",
    "\n",
    "\n",
    "        return len(new_images)\n",
    "\n",
    "    def save_images_labels_size(self, size, faceDetector, path_output):\n",
    "        # images_paths, labels_paths = getDataAndLabelsPath()\n",
    "        # images = []\n",
    "        # labels = []\n",
    "        #\n",
    "        # # for path in enumerate(paths):\n",
    "        # for path in labels_paths:\n",
    "        #     label = np.load(path).tolist()\n",
    "        #     labels += label\n",
    "        #     print(\"len_label: \", len(label))\n",
    "        # print(\"len: \", len(labels))\n",
    "\n",
    "        # self.generate_labels(save=True, path_output=path_output)\n",
    "        self.generate_images_with_size(size, save=True, faceDetector=faceDetector, path_output=path_output)\n",
    "\n",
    "    def make_dirs(self, path):\n",
    "        if os.path.exists(path) == False:\n",
    "            os.makedirs(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3u7O2IUxxPuU"
   },
   "source": [
    "# **`Parameters Fine-Tuning`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d_VS4D3OxBIt"
   },
   "outputs": [],
   "source": [
    "COMMENTARY = \"teste mobilenetv2 with all databases\"\n",
    "\n",
    "IMG_SIZE = 185\n",
    "\n",
    "BATCH_SIZE = 35\n",
    "\n",
    "OPTIMIZERS = [\"Adadelta\", \"SGD\", \"Nadam\", \"RMSprop\", \"Adam\"]\n",
    "OPTIMIZER = OPTIMIZERS[0]\n",
    "\n",
    "ARCHITECTURES = [\"VGG16\", \"VGG19\", \"MobileNet\", \"MobileNetV2\", \\\n",
    "                \"ResNet50\", \"InceptionV3\", \"InceptionResNetV2\", \"NASNetLarge\", \\\n",
    "                \"Xception\"]\n",
    "ARCHITECTURE = ARCHITECTURES[4-1]\n",
    "\n",
    "NUM_CLASSES = 7\n",
    "EPOCHS = 40\n",
    "\n",
    "#how many epochs waiting a increasing in validation loss\n",
    "PATIENCE = 6\n",
    "\n",
    "#parameters learning rate schedule\n",
    "INITIAL_LRATE=0.05 \n",
    "#LIMIT_INF = 0.005\n",
    "LIMIT_INF = 0.005\n",
    "DROP=0.75 \n",
    "EPOCHS_DROP=1.0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KJf1OZusTp57"
   },
   "source": [
    "# Loading Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "isASoAf4AS4m",
    "outputId": "9e9dcaef-a69d-4511-bd29-b7881159c9e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[+] LOADING BASE INPUT\n",
      "[+] PERFECT, IT'S LOADED THE INPUT BASE\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "preProcessing = PreProcessing()\n",
    "\n",
    "\n",
    "ROOT_INPUT_DATA = \"input_data_emotions\"\n",
    "BASE_DIR = \"output_\"+str(IMG_SIZE)\n",
    "\n",
    "\n",
    "input_path = os.path.join(ROOT_INPUT_DATA, BASE_DIR)\n",
    "print(\"[+] LOADING BASE INPUT\")\n",
    "x_train, y_train, x_test, y_test = preProcessing.load_base_input_experiment(input_path)\n",
    "print(\"[+] PERFECT, IT'S LOADED THE INPUT BASE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qJ5ljo3vAIqf"
   },
   "source": [
    "# **`Train Script`**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 897
    },
    "colab_type": "code",
    "id": "0ABbKJNSkx9u",
    "outputId": "2f39eb74-1262-4168-f9d5-a5fca44bf8b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (38868, 185, 185, 3)\n",
      "38868 train samples\n",
      "[+] TYPE NDARRAY:  uint8\n",
      "[+] MobileNetV2\n",
      "[+] BUILD NET\n",
      "[+] COMPILE\n",
      "[+] OPTIMIZER:  Adadelta\n",
      "[+] ADD COMMENTARY\n",
      "[+] TRAIN\n",
      "[+] BATCH_SIZE:  35\n",
      "Train on 38868 samples, validate on 12961 samples\n",
      "Epoch 1/40\n",
      "[+] initial:  0.05\n",
      "[+] ANTIGO K:  0.05\n",
      "[+] NOVO:  0.05\n",
      "38868/38868 [==============================] - 379s 10ms/step - loss: 4.4573 - acc: 0.1480 - val_loss: 3.4524 - val_acc: 0.2610\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.45237, saving model to mestrado_finish/FINAL-MobileNetV2+185+22_14_42+2019-04-22/weights.01-3.45.hdf5\n",
      "Epoch 2/40\n",
      "[+] initial:  0.05\n",
      "[+] ANTIGO K:  0.05\n",
      "[+] NOVO:  0.028125\n",
      "38868/38868 [==============================] - 362s 9ms/step - loss: 2.0208 - acc: 0.2902 - val_loss: 2.0428 - val_acc: 0.2986\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.45237 to 2.04278, saving model to mestrado_finish/FINAL-MobileNetV2+185+22_14_42+2019-04-22/weights.02-2.04.hdf5\n",
      "Epoch 3/40\n",
      "[+] initial:  0.05\n",
      "[+] ANTIGO K:  0.028125\n",
      "[+] NOVO:  0.02109375\n",
      "38868/38868 [==============================] - 362s 9ms/step - loss: 1.9854 - acc: 0.2908 - val_loss: 2.0065 - val_acc: 0.2950\n",
      "\n",
      "Epoch 00003: val_loss improved from 2.04278 to 2.00654, saving model to mestrado_finish/FINAL-MobileNetV2+185+22_14_42+2019-04-22/weights.03-2.01.hdf5\n",
      "Epoch 4/40\n",
      "[+] initial:  0.05\n",
      "[+] ANTIGO K:  0.02109375\n",
      "[+] NOVO:  0.0158203125\n",
      "38850/38868 [============================>.] - ETA: 0s - loss: 1.9718 - acc: 0.2911"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "utils = Utils()\n",
    "\n",
    "\n",
    "ROOT_OUTPUT = \"mestrado_finish\"\n",
    "EXPERIMENT_ID = \"FINAL-\" + ARCHITECTURE + \"+\" + str(IMG_SIZE) + \"+\" + utils.get_date_string()\n",
    "output_path = os.path.join(ROOT_OUTPUT, EXPERIMENT_ID)\n",
    "utils.make_dirs(output_path)\n",
    "# output_path = drive.create_dir(top=ROOT_OUTPUT, name=EXPERIMENT_ID)\n",
    "\n",
    "\n",
    "common = Common(INITIAL_LRATE, DROP, EPOCHS_DROP, LIMIT_INF)\n",
    "\n",
    "common.write_file_info(output_path, [\"architecture: \" + ARCHITECTURE, \"img_size: \" + str(IMG_SIZE)])\n",
    "\n",
    "input_shape = (IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "#NORMALIZE IMAGES DATASET\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_train /= 255.0\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "\n",
    "print(\"[+] TYPE NDARRAY: \", x_train.dtype)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "    print(\"[+] \" + ARCHITECTURE)\n",
    "    if ARCHITECTURE == \"VGG16\":\n",
    "        net = VGG16()\n",
    "    elif ARCHITECTURE == \"VGG19\":\n",
    "        net = VGG19()\n",
    "    elif ARCHITECTURE == \"MobileNet\":\n",
    "        net = MobileNet()\n",
    "    elif ARCHITECTURE == \"MobileNetV2\":\n",
    "        net = MobileNetV2()\n",
    "    elif ARCHITECTURE == \"ResNet50\":\n",
    "        net = ResNet50()\n",
    "    elif ARCHITECTURE == \"InceptionV3\":\n",
    "        net = InceptionV3()\n",
    "    elif ARCHITECTURE == \"InceptionResNetV2\":\n",
    "        net = InceptionResNetV2()\n",
    "    elif ARCHITECTURE == \"NASNetLarge\":\n",
    "        net = NASNetLarge()\n",
    "    elif ARCHITECTURE == \"Xception\":\n",
    "        net = Xception()\n",
    "\n",
    "\n",
    "        \n",
    "    print(\"[+] BUILD NET\")\n",
    "    model = net.build_network(input_shape, NUM_CLASSES)\n",
    "\n",
    "    print(\"[+] COMPILE\")\n",
    "    model = common.compile_net(model, output_path, OPTIMIZER)\n",
    "\n",
    "    print(\"[+] ADD COMMENTARY\")\n",
    "    common.addCommentary(output_path, COMMENTARY)\n",
    "    \n",
    "    print(\"[+] TRAIN\")\n",
    "    model, history = common.train(model, x_train, y_train, x_test, y_test, BATCH_SIZE, EPOCHS, output_path, PATIENCE)\n",
    "\n",
    "    print(\"[+] SAVE ON HISTORY\")\n",
    "    common.save_plot_losses(history, output_path)\n",
    "    common.save_plot_acc(history, output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oALdurXMTGMu"
   },
   "source": [
    "# Restore model and Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b1eQ0CqqlQXg"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "common = Common()\n",
    "\n",
    "RECOVERY_PATH = \"InceptionResNetV2+185+19_57_04+2018-12-04\"\n",
    "\n",
    "\n",
    "ROOT_OUTPUT = \"/content/drive/My Drive/mestrado_finish/experimentos\"\n",
    "\n",
    "output_path = os.path.join(ROOT_OUTPUT, RECOVERY_PATH)\n",
    "\n",
    "#NORMALIZE IMAGES DATASET\n",
    "# x_train = x_train.astype('float32')\n",
    "# x_train /= 255.0\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "\n",
    "print(\"[+] TYPE NDARRAY: \", x_train.dtype)\n",
    "\n",
    "with tf.device('/gpu:0'):\n",
    "#     print(\"[+] \" + ARCHITECTURE)\n",
    "#     if ARCHITECTURE == \"VGG16\":\n",
    "#         net = VGG16()\n",
    "#     elif ARCHITECTURE == \"VGG19\":\n",
    "#         net = VGG19()\n",
    "#     elif ARCHITECTURE == \"MobileNet\":\n",
    "#         net = MobileNet()\n",
    "#     elif ARCHITECTURE == \"MobileNetV2\":\n",
    "#         net = MobileNetV2()\n",
    "#     elif ARCHITECTURE == \"ResNet50\":\n",
    "#         net = ResNet50()\n",
    "#     elif ARCHITECTURE == \"InceptionV3\":\n",
    "#         net = InceptionV3()\n",
    "#     elif ARCHITECTURE == \"InceptionResNetV2\":\n",
    "#         net = InceptionResNetV2()\n",
    "\n",
    "\n",
    "    print(\"[+] RESTORE LAST MODEL\")\n",
    "    model = common.last_load_model_net(output_path)\n",
    "\n",
    "    print(\"[+] COMPILE\")\n",
    "    model = common.compile_net(model, output_path, OPTIMIZER)\n",
    "\n",
    "    print(\"[+] TRAIN\")\n",
    "    model, history = common.train(model, x_train, y_train, x_test, y_test, BATCH_SIZE, EPOCHS, output_path, PATIENCE)\n",
    "\n",
    "    print(\"[+] SAVE ON HISTORY\")\n",
    "    common.save_plot_losses(history, output_path)\n",
    "    common.save_plot_acc(history, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zQN0eVd4dMtb"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "final_train_colab_keras.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
